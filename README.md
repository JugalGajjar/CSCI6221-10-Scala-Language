# Scala Big Data Processing Pipeline

## Introduction
This project demonstrates the development of an end-to-end big data processing pipeline using Scala. The pipeline efficiently handles the ingestion, storage, processing, and analysis of large datasets to provide real-time, actionable insights. Built on top of the Java Virtual Machine (JVM), Scala combines object-oriented and functional programming paradigms, making it an excellent choice for distributed computing and real-time data processing systems.

## Features
1. **Data Ingestion**: Seamlessly ingest large volumes of data from multiple sources.
2. **Data Storage**: Use scalable storage systems to ensure fault tolerance and manage data consistency.
3. **Data Processing**: Process vast datasets using efficient distributed computing frameworks.
4. **Data Transformation**: Transform raw data into structured, useful formats for further analysis.
5. **Data Analysis**: Generate insights from processed data, facilitating real-time decision-making.
6. **Logging and Monitoring**: Track system performance and data flow with integrated logging and monitoring tools.

## Technologies Used
- **Scala**: The core programming language used for building and managing the pipeline.
- **Apache Spark**: To process and analyze large datasets in a distributed environment.
- **Hadoop Distributed File System (HDFS)**: A scalable and reliable storage system for managing large-scale data.
- **Spark SQL/DataFrames**: For querying and manipulating structured data in a flexible way.
- **Grafana**: For creating interactive dashboards.

## Use Cases
- **E-Commerce**: Track customer behavior and make personalized recommendations in real-time.
- **Healthcare**: Process medical data to provide instant diagnostic insights.
- **Finance**: Detect fraud and automate trading decisions based on real-time data analysis.
- **Telecommunications**: Optimize network usage by analyzing traffic patterns.
- **Internet of Things (IoT)**: Analyze large amounts of sensor data from connected devices.

## Project Demo Video
- https://drive.google.com/file/d/1Gf3NFdqovI7JXxbWT83lpXTO0nAxS3j4/view

## Steps To Use
- Install Java
- Install MySQL
- Setup Scala, Spark, Hadoop, and Grafana
- Clone this repository
- Create a MySQL database of name "YoutubeStatsDb"
- Open YouTubeAnalysis.scala in an IDE (such as IntelliJ)
- Add your own YouTube API Key in the key placeholder
- Update the absolute paths to the files
- Add your own MySQL username and password for the database connectivity
- Make Grafana to connect with your MySQL database and add relevant queries for the visualizations
- Execute YouTubeAnalysis.scala

## Contributors
- Jugal Gajjar
- Kaustik Ranaware
- Michael Womack
- Saurabh S. R.
- Saptorshee Nag
